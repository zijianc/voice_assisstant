# ğŸ”§ è¯­éŸ³åŠ©æ‰‹æŠ€æœ¯å®ç°ç»†èŠ‚

æœ¬æ–‡æ¡£è¡¥å……äº†å…·ä½“çš„ä»£ç å®ç°ç»†èŠ‚å’ŒæŠ€æœ¯å†³ç­–è¯´æ˜ã€‚

## ğŸ“ æ ¸å¿ƒä»£ç å˜æ›´æ€»è§ˆ

### 1. TTSèŠ‚ç‚¹ä¼˜åŒ– (`openai_tts_node.py`)

#### å…³é”®å˜æ›´
```python
# ä¿®å¤çº¿ç¨‹æ± å‘½åå†²çª (ç¬¬50è¡Œ)
- self.executor = ThreadPoolExecutor(max_workers=2)
+ self.thread_executor = ThreadPoolExecutor(max_workers=2)

# ä½¿ç”¨æœ€æ–°APIé…ç½® (ç¬¬52-56è¡Œ)
self.tts_model = os.environ.get("TTS_MODEL", "gpt-4o-mini-tts")
self.tts_voice = os.environ.get("TTS_VOICE", "coral")
self.tts_format = os.environ.get("TTS_FORMAT", "wav")
self.tts_speed = float(os.environ.get("TTS_SPEED", "1.1"))

# å¼‚æ­¥TTSè°ƒç”¨ (ç¬¬92è¡Œ)
- self.executor.submit(self.call_openai_tts_async, text)
+ self.thread_executor.submit(self.call_openai_tts_async, text)
```

#### æ’­æ”¾å™¨æ”¹è¿›
```python
def play_audio_with_pygame(self, audio_content: bytes):
    """æ”¹è¿›çš„pygameéŸ³é¢‘æ’­æ”¾å™¨"""
    try:
        # ç¡®ä¿æ¸…ç†ä¹‹å‰çš„éŸ³é¢‘çŠ¶æ€
        pygame.mixer.quit()
        pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{self.tts_format}') as temp_file:
            temp_file.write(audio_content)
            temp_filename = temp_file.name
        
        # æ’­æ”¾éŸ³é¢‘
        pygame.mixer.music.load(temp_filename)
        pygame.mixer.music.play()
        
        # ç­‰å¾…æ’­æ”¾å®Œæˆ
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
            
    finally:
        # æ¸…ç†èµ„æº
        if temp_filename and os.path.exists(temp_filename):
            os.unlink(temp_filename)
        pygame.mixer.quit()
```

### 2. STTå®æ—¶èŠ‚ç‚¹ (`realtime_stt_node.py`)

#### VADå®ç°æ ¸å¿ƒ
```python
class RealtimeSTTNode(Node):
    def __init__(self):
        super().__init__('realtime_stt_node')
        
        # VADå‚æ•°é…ç½®
        self.rms_threshold = 1000          # åˆå§‹RMSé˜ˆå€¼
        self.silence_duration = 2.0        # é™éŸ³åˆ¤å®šæ—¶é—´
        self.min_speech_duration = 0.5     # æœ€å°è¯­éŸ³é•¿åº¦
        self.max_speech_duration = 10.0    # æœ€å¤§è¯­éŸ³é•¿åº¦
        
        # éŸ³é¢‘å‚æ•°
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        
    def is_speech(self, audio_chunk):
        """åŸºäºRMSçš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹"""
        audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
        rms = np.sqrt(np.mean(audio_data**2))
        
        # åŠ¨æ€é˜ˆå€¼è°ƒæ•´
        if rms < self.rms_threshold * 0.3:
            self.rms_threshold *= 0.95  # é€æ¸é™ä½é˜ˆå€¼
        elif rms > self.rms_threshold * 2:
            self.rms_threshold *= 1.05  # é€æ¸æé«˜é˜ˆå€¼
            
        return rms > self.rms_threshold
```

#### è¯­éŸ³ç¼“å†²ç®¡ç†
```python
def process_audio_stream(self):
    """æ™ºèƒ½éŸ³é¢‘æµå¤„ç†"""
    audio_buffer = []
    silence_count = 0
    speech_detected = False
    
    while not self.stop_recording:
        try:
            data = self.stream.read(self.chunk, exception_on_overflow=False)
            
            if self.is_speech(data):
                if not speech_detected:
                    self.get_logger().info("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                    speech_detected = True
                    
                audio_buffer.append(data)
                silence_count = 0
            else:
                if speech_detected:
                    silence_count += 1
                    audio_buffer.append(data)  # ä¿ç•™ä¸€äº›é™éŸ³ç”¨äºè‡ªç„¶ç»“æŸ
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™éŸ³é˜ˆå€¼
                    if silence_count > (self.silence_duration * self.rate / self.chunk):
                        self.submit_audio_for_recognition(audio_buffer)
                        audio_buffer = []
                        speech_detected = False
                        silence_count = 0
                        
        except Exception as e:
            self.get_logger().error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
```

### 3. LLMæ™ºèƒ½å¯¹è¯ç³»ç»Ÿ (`llm_node.py`)

#### ğŸ§  å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†
```python
class LLMNode(Node):
    def __init__(self):
        # åˆå§‹åŒ–å¯¹è¯å†å²å­˜å‚¨
        self.conversation_history: list[dict[str, str]] = []  # å­˜å‚¨ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯
        self.max_history_messages = 20   # ä¿æŒæœ€è¿‘20æ¡æ¶ˆæ¯ (10è½®å¯¹è¯)
        
        # åˆå§‹åŒ–RAGçŸ¥è¯†åº“
        try:
            self.knowledge_base = UWAKnowledgeBase()
            self.get_logger().info("âœ… RAG Knowledge Base initialized successfully")
        except Exception as e:
            self.get_logger().error(f"âŒ Failed to initialize Knowledge Base: {e}")
            self.knowledge_base = None

    def call_chatgpt_with_rag(self, prompt: str) -> str:
        """å¢å¼ºç‰ˆChatGPTè°ƒç”¨ï¼Œé›†æˆRAGå’Œå¯¹è¯å†å²"""
        
        # æ­¥éª¤1: æœç´¢ç›¸å…³çŸ¥è¯†
        search_results = self.search_knowledge_base(prompt, n_results=3)
        rag_context = self.format_rag_context(search_results)
        
        # æ­¥éª¤2: æ„å»ºåŒ…å«å†å²çš„æ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å² (æ§åˆ¶tokenä½¿ç”¨)
        if self.conversation_history:
            messages.extend(self.conversation_history[-self.max_history_messages:])
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": prompt})
        
        # æ­¥éª¤3: è°ƒç”¨OpenAI API
        response = self.client.chat.completions.create(
            model="ft:gpt-4.1-mini-2025-04-14:personal:my-voice-assistant:BxxCKJUa",
            messages=messages,
            temperature=0.7,
            max_tokens=1024,
            stream=True
        )
        
        # æ­¥éª¤4: æ›´æ–°å¯¹è¯å†å²
        self.conversation_history.append({"role": "user", "content": prompt})
        self.conversation_history.append({"role": "assistant", "content": final_filtered})
        
        # æ­¥éª¤5: ç»´æŠ¤å†å²é•¿åº¦
        if len(self.conversation_history) > self.max_history_messages:
            excess = len(self.conversation_history) - self.max_history_messages
            self.conversation_history = self.conversation_history[excess:]
```

#### ğŸ” RAGçŸ¥è¯†æ£€ç´¢ç³»ç»Ÿ
```python
def search_knowledge_base(self, query: str, n_results: int = 3):
    """æœç´¢UWAçŸ¥è¯†åº“è·å–ç›¸å…³ä¿¡æ¯"""
    if not self.knowledge_base:
        return []
        
    try:
        results = self.knowledge_base.search(query, n_results=n_results)
        
        if results:
            self.get_logger().info(f"ğŸ” Found {len(results)} relevant knowledge entries")
            for i, result in enumerate(results):
                self.get_logger().debug(f"  {i+1}. [{result['metadata']['category']}] "
                                      f"{result['content'][:50]}... (distance: {result['distance']:.3f})")
        return results
        
    except Exception as e:
        self.get_logger().error(f"âŒ Knowledge search error: {e}")
        return []

def format_rag_context(self, search_results: list) -> str:
    """å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºLLMä¸Šä¸‹æ–‡"""
    if not search_results:
        return ""
        
    context_parts = ["ğŸ“š RELEVANT UWA INFORMATION:"]
    
    for i, result in enumerate(search_results, 1):
        building = result['metadata'].get('building', 'Unknown')
        category = result['metadata'].get('category', 'general')
        content = result['content']
        
        context_parts.append(f"{i}. [{category.upper()}] {content}")
        if building != 'Campus General' and building != 'unknown':
            context_parts[-1] += f" (Located: {building})"
    
    context_parts.append("\nPlease use this information to provide accurate, helpful responses about UWA.")
    
    return "\n".join(context_parts)
```

#### ğŸ§¹ å†…å®¹è¿‡æ»¤å™¨è¯¦ç»†å®ç°
```python
def filter_content(self, text: str) -> str:
    """å¤šå±‚æ¬¡å†…å®¹è¿‡æ»¤å™¨"""
    if not text:
        return text
        
    original_length = len(text)
    
    # ç¬¬ä¸€å±‚ï¼šç§»é™¤ã€ã€‘æ‹¬å·å†…å®¹
    # åŒ¹é…æ¨¡å¼ï¼šã€ä»»ä½•éã€‘å­—ç¬¦ã€‘
    filtered_text = re.sub(r'ã€[^ã€‘]*ã€‘', '', text)
    
    # ç¬¬äºŒå±‚ï¼šç§»é™¤æ•°å­—å¼•ç”¨æ¨¡å¼
    # ç§»é™¤3ä½ä»¥ä¸Šè¿ç»­æ•°å­—
    filtered_text = re.sub(r'\b\d{3,}\b', '', filtered_text)
    
    # ç¬¬ä¸‰å±‚ï¼šç§»é™¤ç‰¹æ®Šç¬¦å·
    # â€  â€‘ ç­‰ç‰¹æ®Šå¼•ç”¨ç¬¦å·
    filtered_text = re.sub(r'[â€ â€‘]+', '', filtered_text)
    
    # ç¬¬å››å±‚ï¼šç§»é™¤è¡Œå·å¼•ç”¨
    # Læ•°å­—-Læ•°å­— æ¨¡å¼
    filtered_text = re.sub(r'L\d+-L\d+', '', filtered_text)
    
    # ç¬¬äº”å±‚ï¼šæ¸…ç†æ ¼å¼
    # åˆå¹¶å¤šä¸ªç©ºæ ¼
    filtered_text = re.sub(r'\s+', ' ', filtered_text)
    # æ¸…ç†è¿ç»­å¥å·
    filtered_text = re.sub(r'\s*\.\s*\.+', '.', filtered_text)
    # ç§»é™¤é¦–å°¾ç©ºç™½
    filtered_text = filtered_text.strip()
    
    # è®°å½•è¿‡æ»¤æ•ˆæœ
    if len(filtered_text) != original_length:
        self.get_logger().info(f"ğŸ§¹ Content filtered: {original_length} -> {len(filtered_text)} chars")
    
    return filtered_text
```

#### ğŸ¯ æ™ºèƒ½åŠŸèƒ½ç‰¹ç‚¹æ€»ç»“

**å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†**:
- âœ… è‡ªåŠ¨ç»´æŠ¤æœ€è¿‘20æ¡æ¶ˆæ¯å†å²
- âœ… æ™ºèƒ½tokenç®¡ç†ï¼Œé¿å…è¶…å‡ºAPIé™åˆ¶
- âœ… å¯¹è¯å†å²è‡ªåŠ¨æˆªæ–­å’Œæ›´æ–°
- âœ… æ”¯æŒå¤šè½®è¿ç»­å¯¹è¯ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§

**RAGçŸ¥è¯†å¢å¼º**:
- âœ… é›†æˆUWAæ ¡å›­çŸ¥è¯†åº“ï¼ˆ44+æ–‡æ¡£ï¼‰
- âœ… å®æ—¶çŸ¥è¯†æ£€ç´¢ï¼Œç›¸å…³åº¦è¯„åˆ†æ’åº
- âœ… åŠ¨æ€ä¸Šä¸‹æ–‡æ³¨å…¥ï¼Œæå‡å›ç­”å‡†ç¡®æ€§  
- âœ… æ”¯æŒå»ºç­‘ç‰©ä½ç½®ã€æœåŠ¡æ—¶é—´ç­‰å…·ä½“ä¿¡æ¯æŸ¥è¯¢

**å†…å®¹è´¨é‡ä¿è¯**:
- âœ… å¤šå±‚è¿‡æ»¤ç®—æ³•ï¼Œè‡ªåŠ¨æ¸…ç†LLMè¾“å‡ºå™ªå£°
- âœ… å®æ—¶å†…å®¹è¿‡æ»¤ï¼Œä¿è¯ç”¨æˆ·ä½“éªŒ
- âœ… è¿‡æ»¤æ•ˆæœè·Ÿè¸ªå’Œæ—¥å¿—è®°å½•
- âœ… æµå¼å“åº”å¤„ç†ï¼Œé™ä½å»¶è¿Ÿæ„ŸçŸ¥

#### ğŸ¥ ç”¨æˆ·äº¤äº’å¢å¼º
```python
def listener_callback(self, msg: String):
    """å¢å¼ºç‰ˆç”¨æˆ·è¾“å…¥å¤„ç†"""
    input_text = msg.data.strip()
    if not input_text:
        return

    # æ¸…æ™°æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    print("\n" + "="*60)
    print("ğŸ¤ ç”¨æˆ·è¯­éŸ³è¾“å…¥:")
    print("-"*60)
    print(f"'{input_text}'")
    print("="*60)
    
    # æ˜¾ç¤ºRAGæœç´¢ç»“æœ
    search_results = self.search_knowledge_base(input_text, n_results=3)
    if search_results:
        print("\n" + "="*60)
        print("ğŸ” RAG çŸ¥è¯†åº“æœç´¢ç»“æœ:")
        print("-"*60)
        for i, result in enumerate(search_results, 1):
            category = result['metadata']['category']
            building = result['metadata']['building']
            content = result['content'][:80] + "..." if len(result['content']) > 80 else result['content']
            distance = result['distance']
            
            print(f"{i}. [{category}] {content}")
            if building not in ['Campus General', 'unknown']:
                print(f"   ğŸ“ ä½ç½®: {building}")
            print(f"   ğŸ“Š ç›¸å…³åº¦: {(1-distance)*100:.1f}%")
        print("="*60)
    
    # æ˜¾ç¤ºå®Œæ•´LLMå›ç­”
    print("\n" + "="*60)
    print("ğŸ¤– LLM å®Œæ•´å›ç­”:")
    print("-"*60)
    print(final_filtered)
    print("="*60 + "\n")
```

### 4. å®æ—¶è¯­éŸ³è¯†åˆ«+VAD (`realtime_stt_node.py`)

#### VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹
```python
def process_audio_chunk(self, audio_data):
    """å¤„ç†éŸ³é¢‘å—å¹¶æ£€æµ‹è¯­éŸ³æ´»åŠ¨"""
    # è®¡ç®—RMSéŸ³é‡
    rms = np.sqrt(np.mean(audio_data**2))
    
    # åŠ¨æ€é˜ˆå€¼æ£€æµ‹
    if rms > self.vad_threshold:
        self.is_speaking = True
        self.speech_buffer.extend(audio_data)
        self.silence_counter = 0
    else:
        self.silence_counter += 1
        
        # è¯­éŸ³ç»“æŸæ£€æµ‹
        if self.is_speaking and self.silence_counter > self.silence_limit:
            self.process_speech_segment()
            self.is_speaking = False
```

## ğŸ§ª æµ‹è¯•éªŒè¯æ–¹æ³•

### 1. æ€§èƒ½æµ‹è¯•è„šæœ¬åˆ†æ

#### `test_tts_performance.sh` å…³é”®éƒ¨åˆ†
```bash
# åŠ¨æ€æµ‹è¯•å‡½æ•°
test_tts_config() {
    local model=$1
    local voice=$2
    local format=$3
    local speed=$4
    local description=$5
    
    # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    export TTS_MODEL=$model
    export TTS_VOICE=$voice
    export TTS_FORMAT=$format
    export TTS_SPEED=$speed
    
    # ç”ŸæˆPythonæµ‹è¯•è„šæœ¬
    cat > temp_tts_test.py << EOF
#!/usr/bin/env python3
import time
import os
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

start_time = time.time()
response = client.audio.speech.create(
    model="$model",
    voice="$voice", 
    input="$TEST_TEXT",
    response_format="$format",
    speed=$speed
)
generation_time = time.time() - start_time
print(f"ç”Ÿæˆæ—¶é—´: {generation_time:.2f} ç§’")
EOF
    
    # æ‰§è¡Œæµ‹è¯•
    python3 temp_tts_test.py
    rm -f temp_tts_test.py
}
```

### 2. å†…å®¹è¿‡æ»¤æµ‹è¯•

#### æµ‹è¯•ç”¨ä¾‹è®¾è®¡
```python
test_cases = [
    # åŸºæœ¬è¿‡æ»¤æµ‹è¯•
    "æ­£å¸¸æ–‡æœ¬ã€éœ€è¦è¿‡æ»¤çš„å†…å®¹ã€‘ä¿ç•™æ–‡æœ¬",
    
    # å¤æ‚å¼•ç”¨è¿‡æ»¤
    "æ–‡æœ¬å†…å®¹ã€742442319583238â€ L62-L65ã€‘ç»§ç»­æ–‡æœ¬",
    
    # å¤šé‡è¿‡æ»¤
    "å¼€å§‹ã€ç¬¬ä¸€ä¸ªã€‘ä¸­é—´ã€ç¬¬äºŒä¸ªã€‘ç»“æŸ",
    
    # è¾¹ç•Œæƒ…å†µ
    "ã€ã€‘ç©ºæ‹¬å·æµ‹è¯•",
    "ã€åµŒå¥—ã€å†…å®¹ã€‘æµ‹è¯•ã€‘",
    
    # æ•°å­—å’Œç¬¦å·
    "åŒ…å«12345å¤§æ•°å­—å’Œâ€ â€‘ç‰¹æ®Šç¬¦å·",
]
```

### 3. é›†æˆæµ‹è¯•æµç¨‹

#### å®Œæ•´æµ‹è¯•åºåˆ—
```bash
#!/bin/bash
echo "ğŸ§ª å¼€å§‹å®Œæ•´ç³»ç»Ÿæµ‹è¯•"

# 1. ç¯å¢ƒæ£€æŸ¥
test_environment() {
    echo "æ£€æŸ¥ç¯å¢ƒå˜é‡..."
    [ -z "$OPENAI_API_KEY" ] && echo "âŒ APIå¯†é’¥ç¼ºå¤±" && return 1
    echo "âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# 2. ç»„ä»¶æµ‹è¯•
test_components() {
    echo "æµ‹è¯•å„ç»„ä»¶..."
    
    # TTSæµ‹è¯•
    ./test_tts_simple.sh || return 1
    
    # å†…å®¹è¿‡æ»¤æµ‹è¯•
    python3 test_content_filter.py || return 1
    
    echo "âœ… ç»„ä»¶æµ‹è¯•é€šè¿‡"
}

# 3. æ€§èƒ½éªŒè¯
test_performance() {
    echo "æ€§èƒ½åŸºå‡†æµ‹è¯•..."
    ./test_tts_performance.sh | grep "ç”Ÿæˆæ—¶é—´" | \
    awk -F: '{print $2}' | awk '{if($1 > 3.0) exit 1}'
    
    [ $? -eq 0 ] && echo "âœ… æ€§èƒ½è¾¾æ ‡" || echo "âŒ æ€§èƒ½ä¸è¾¾æ ‡"
}

# 4. é›†æˆæµ‹è¯•
test_integration() {
    echo "ROS2é›†æˆæµ‹è¯•..."
    
    # å¯åŠ¨èŠ‚ç‚¹
    ./start_tts_fast.sh &
    TTS_PID=$!
    sleep 3
    
    # å‘é€æµ‹è¯•æ¶ˆæ¯
    ros2 topic pub /llm_response std_msgs/String \
        "data: 'Helloã€test123ã€‘world'" --once
    
    # æ¸…ç†
    kill $TTS_PID 2>/dev/null
    echo "âœ… é›†æˆæµ‹è¯•å®Œæˆ"
}

# æ‰§è¡Œæµ‹è¯•åºåˆ—
test_environment && \
test_components && \
test_performance && \
test_integration

echo "ğŸ ç³»ç»Ÿæµ‹è¯•å®Œæˆ"
```

## âš™ï¸ é…ç½®ç®¡ç†

### ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§
```bash
# 1. ç³»ç»Ÿç¯å¢ƒå˜é‡ (æœ€é«˜ä¼˜å…ˆçº§)
export TTS_MODEL=gpt-4o-mini-tts

# 2. .env æ–‡ä»¶é…ç½®
TTS_MODEL=gpt-4o-mini-tts

# 3. ä»£ç é»˜è®¤å€¼ (æœ€ä½ä¼˜å…ˆçº§)
self.tts_model = os.environ.get("TTS_MODEL", "tts-1")
```

### åŠ¨æ€é…ç½®æ›´æ–°
```python
class ConfigManager:
    def __init__(self):
        self.config_file = ".env"
        self.load_config()
        
    def load_config(self):
        """ä».envæ–‡ä»¶åŠ è½½é…ç½®"""
        if os.path.exists(self.config_file):
            load_dotenv(self.config_file)
            
    def update_config(self, key: str, value: str):
        """åŠ¨æ€æ›´æ–°é…ç½®"""
        os.environ[key] = value
        self.save_to_file(key, value)
        
    def save_to_file(self, key: str, value: str):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        # å®ç°é…ç½®æŒä¹…åŒ–
        pass
```

## ğŸ” æ•…éšœè¯Šæ–­æŒ‡å—

### å¸¸è§é—®é¢˜æ’æŸ¥

#### 1. TTSå“åº”æ…¢
```bash
# æ£€æŸ¥æ¨¡å‹é…ç½®
echo $TTS_MODEL  # åº”è¯¥æ˜¯ gpt-4o-mini-tts

# æ£€æŸ¥æ ¼å¼é…ç½®  
echo $TTS_FORMAT  # æ¨è opus æˆ– wav

# æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
curl -w "@curl-format.txt" -o /dev/null -s "https://api.openai.com/v1/models"
```

#### 2. å†…å®¹è¿‡æ»¤å¤±æ•ˆ
```python
# æµ‹è¯•è¿‡æ»¤å™¨
def test_filter():
    test_text = "Helloã€test123ã€‘world"
    result = filter_content(test_text)
    assert "ã€" not in result, "è¿‡æ»¤å™¨å¤±æ•ˆ"
    print(f"è¿‡æ»¤æµ‹è¯•: '{test_text}' -> '{result}'")
```

#### 3. STT VADæ•æ„Ÿåº¦
```python
# è°ƒæ•´VADå‚æ•°
def tune_vad():
    # ç¯å¢ƒå™ªéŸ³å¤§æ—¶æé«˜é˜ˆå€¼
    self.rms_threshold = 1500
    
    # å®‰é™ç¯å¢ƒæ—¶é™ä½é˜ˆå€¼
    self.rms_threshold = 800
    
    # åŠ¨æ€è°ƒæ•´
    self.adaptive_threshold = True
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡
- **TTSå»¶è¿Ÿ**: < 2.5ç§’
- **å†…å­˜ä½¿ç”¨**: < 500MB
- **CPUä½¿ç”¨**: < 50%
- **é”™è¯¯ç‡**: < 1%

### ç›‘æ§å®ç°
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'tts_latency': [],
            'memory_usage': [],
            'error_count': 0
        }
    
    def record_tts_latency(self, latency: float):
        self.metrics['tts_latency'].append(latency)
        if latency > 3.0:
            self.alert_slow_tts(latency)
    
    def get_average_latency(self) -> float:
        latencies = self.metrics['tts_latency']
        return sum(latencies) / len(latencies) if latencies else 0
```

---

*æŠ€æœ¯å®ç°æ–‡æ¡£ v1.0*  
*æ›´æ–°æ—¶é—´: 2025å¹´7æœˆ27æ—¥*
