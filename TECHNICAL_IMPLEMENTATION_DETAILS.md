# ğŸ”§ è¯­éŸ³åŠ©æ‰‹æŠ€æœ¯å®ç°ç»†èŠ‚

æœ¬æ–‡æ¡£è¡¥å……äº†å…·ä½“çš„ä»£ç å®ç°ç»†èŠ‚å’ŒæŠ€æœ¯å†³ç­–è¯´æ˜ã€‚

## ğŸ“ æ ¸å¿ƒä»£ç å˜æ›´æ€»è§ˆ

### 1. TTSèŠ‚ç‚¹ä¼˜åŒ– (`openai_tts_node.py`)

#### å…³é”®å˜æ›´
```python
# ä¿®å¤çº¿ç¨‹æ± å‘½åå†²çª (ç¬¬50è¡Œ)
- self.executor = ThreadPoolExecutor(max_workers=2)
+ self.thread_executor = ThreadPoolExecutor(max_workers=2)

# ä½¿ç”¨æœ€æ–°APIé…ç½® (ç¬¬52-56è¡Œ)
self.tts_model = os.environ.get("TTS_MODEL", "gpt-4o-mini-tts")
self.tts_voice = os.environ.get("TTS_VOICE", "coral")
self.tts_format = os.environ.get("TTS_FORMAT", "wav")
self.tts_speed = float(os.environ.get("TTS_SPEED", "1.1"))

# å¼‚æ­¥TTSè°ƒç”¨ (ç¬¬92è¡Œ)
- self.executor.submit(self.call_openai_tts_async, text)
+ self.thread_executor.submit(self.call_openai_tts_async, text)
```

#### æ’­æ”¾å™¨æ”¹è¿›
```python
def play_audio_with_pygame(self, audio_content: bytes):
    """æ”¹è¿›çš„pygameéŸ³é¢‘æ’­æ”¾å™¨"""
    try:
        # ç¡®ä¿æ¸…ç†ä¹‹å‰çš„éŸ³é¢‘çŠ¶æ€
        pygame.mixer.quit()
        pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{self.tts_format}') as temp_file:
            temp_file.write(audio_content)
            temp_filename = temp_file.name
        
        # æ’­æ”¾éŸ³é¢‘
        pygame.mixer.music.load(temp_filename)
        pygame.mixer.music.play()
        
        # ç­‰å¾…æ’­æ”¾å®Œæˆ
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
            
    finally:
        # æ¸…ç†èµ„æº
        if temp_filename and os.path.exists(temp_filename):
            os.unlink(temp_filename)
        pygame.mixer.quit()
```

### 2. STTå®æ—¶èŠ‚ç‚¹ (`realtime_stt_node.py`)

#### VADå®ç°æ ¸å¿ƒ
```python
class RealtimeSTTNode(Node):
    def __init__(self):
        super().__init__('realtime_stt_node')
        
        # VADå‚æ•°é…ç½®
        self.rms_threshold = 1000          # åˆå§‹RMSé˜ˆå€¼
        self.silence_duration = 2.0        # é™éŸ³åˆ¤å®šæ—¶é—´
        self.min_speech_duration = 0.5     # æœ€å°è¯­éŸ³é•¿åº¦
        self.max_speech_duration = 10.0    # æœ€å¤§è¯­éŸ³é•¿åº¦
        
        # éŸ³é¢‘å‚æ•°
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        
    def is_speech(self, audio_chunk):
        """åŸºäºRMSçš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹"""
        audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
        rms = np.sqrt(np.mean(audio_data**2))
        
        # åŠ¨æ€é˜ˆå€¼è°ƒæ•´
        if rms < self.rms_threshold * 0.3:
            self.rms_threshold *= 0.95  # é€æ¸é™ä½é˜ˆå€¼
        elif rms > self.rms_threshold * 2:
            self.rms_threshold *= 1.05  # é€æ¸æé«˜é˜ˆå€¼
            
        return rms > self.rms_threshold
```

#### è¯­éŸ³ç¼“å†²ç®¡ç†
```python
def process_audio_stream(self):
    """æ™ºèƒ½éŸ³é¢‘æµå¤„ç†"""
    audio_buffer = []
    silence_count = 0
    speech_detected = False
    
    while not self.stop_recording:
        try:
            data = self.stream.read(self.chunk, exception_on_overflow=False)
            
            if self.is_speech(data):
                if not speech_detected:
                    self.get_logger().info("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                    speech_detected = True
                    
                audio_buffer.append(data)
                silence_count = 0
            else:
                if speech_detected:
                    silence_count += 1
                    audio_buffer.append(data)  # ä¿ç•™ä¸€äº›é™éŸ³ç”¨äºè‡ªç„¶ç»“æŸ
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é™éŸ³é˜ˆå€¼
                    if silence_count > (self.silence_duration * self.rate / self.chunk):
                        self.submit_audio_for_recognition(audio_buffer)
                        audio_buffer = []
                        speech_detected = False
                        silence_count = 0
                        
        except Exception as e:
            self.get_logger().error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
```

### 3. LLMå†…å®¹è¿‡æ»¤ (`llm_node.py`)

#### è¿‡æ»¤å™¨è¯¦ç»†å®ç°
```python
def filter_content(self, text: str) -> str:
    """å¤šå±‚æ¬¡å†…å®¹è¿‡æ»¤å™¨"""
    if not text:
        return text
        
    original_length = len(text)
    
    # ç¬¬ä¸€å±‚ï¼šç§»é™¤ã€ã€‘æ‹¬å·å†…å®¹
    # åŒ¹é…æ¨¡å¼ï¼šã€ä»»ä½•éã€‘å­—ç¬¦ã€‘
    filtered_text = re.sub(r'ã€[^ã€‘]*ã€‘', '', text)
    
    # ç¬¬äºŒå±‚ï¼šç§»é™¤æ•°å­—å¼•ç”¨æ¨¡å¼
    # ç§»é™¤3ä½ä»¥ä¸Šè¿ç»­æ•°å­—
    filtered_text = re.sub(r'\b\d{3,}\b', '', filtered_text)
    
    # ç¬¬ä¸‰å±‚ï¼šç§»é™¤ç‰¹æ®Šç¬¦å·
    # â€  â€‘ ç­‰ç‰¹æ®Šå¼•ç”¨ç¬¦å·
    filtered_text = re.sub(r'[â€ â€‘]+', '', filtered_text)
    
    # ç¬¬å››å±‚ï¼šç§»é™¤è¡Œå·å¼•ç”¨
    # Læ•°å­—-Læ•°å­— æ¨¡å¼
    filtered_text = re.sub(r'L\d+-L\d+', '', filtered_text)
    
    # ç¬¬äº”å±‚ï¼šæ¸…ç†æ ¼å¼
    # åˆå¹¶å¤šä¸ªç©ºæ ¼
    filtered_text = re.sub(r'\s+', ' ', filtered_text)
    # æ¸…ç†è¿ç»­å¥å·
    filtered_text = re.sub(r'\s*\.\s*\.+', '.', filtered_text)
    # ç§»é™¤é¦–å°¾ç©ºç™½
    filtered_text = filtered_text.strip()
    
    # è®°å½•è¿‡æ»¤æ•ˆæœ
    if len(filtered_text) != original_length:
        self.get_logger().info(f"å†…å®¹è¿‡æ»¤: {original_length}å­—ç¬¦ -> {len(filtered_text)}å­—ç¬¦")
    
    return filtered_text
```

#### é›†æˆåˆ°LLMå“åº”æµ
```python
def llm_response_callback(self, msg):
    """å¤„ç†LLMå“åº”å¹¶åº”ç”¨è¿‡æ»¤"""
    raw_response = msg.data
    
    # åº”ç”¨å†…å®¹è¿‡æ»¤
    filtered_response = self.filter_content(raw_response)
    
    # éªŒè¯è¿‡æ»¤ç»“æœ
    if not filtered_response.strip():
        self.get_logger().warn("è¿‡æ»¤åå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡å‘å¸ƒ")
        return
        
    if len(filtered_response) < len(raw_response) * 0.3:
        self.get_logger().warn("è¿‡æ»¤æ‰è¿‡å¤šå†…å®¹ï¼Œè¯·æ£€æŸ¥è¿‡æ»¤è§„åˆ™")
    
    # å‘å¸ƒæ¸…æ´å†…å®¹
    clean_msg = String(data=filtered_response)
    self.response_publisher.publish(clean_msg)
    
    self.get_logger().info(f"å‘å¸ƒè¿‡æ»¤åå“åº”: {filtered_response[:50]}...")
```

## ğŸ§ª æµ‹è¯•éªŒè¯æ–¹æ³•

### 1. æ€§èƒ½æµ‹è¯•è„šæœ¬åˆ†æ

#### `test_tts_performance.sh` å…³é”®éƒ¨åˆ†
```bash
# åŠ¨æ€æµ‹è¯•å‡½æ•°
test_tts_config() {
    local model=$1
    local voice=$2
    local format=$3
    local speed=$4
    local description=$5
    
    # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    export TTS_MODEL=$model
    export TTS_VOICE=$voice
    export TTS_FORMAT=$format
    export TTS_SPEED=$speed
    
    # ç”ŸæˆPythonæµ‹è¯•è„šæœ¬
    cat > temp_tts_test.py << EOF
#!/usr/bin/env python3
import time
import os
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

start_time = time.time()
response = client.audio.speech.create(
    model="$model",
    voice="$voice", 
    input="$TEST_TEXT",
    response_format="$format",
    speed=$speed
)
generation_time = time.time() - start_time
print(f"ç”Ÿæˆæ—¶é—´: {generation_time:.2f} ç§’")
EOF
    
    # æ‰§è¡Œæµ‹è¯•
    python3 temp_tts_test.py
    rm -f temp_tts_test.py
}
```

### 2. å†…å®¹è¿‡æ»¤æµ‹è¯•

#### æµ‹è¯•ç”¨ä¾‹è®¾è®¡
```python
test_cases = [
    # åŸºæœ¬è¿‡æ»¤æµ‹è¯•
    "æ­£å¸¸æ–‡æœ¬ã€éœ€è¦è¿‡æ»¤çš„å†…å®¹ã€‘ä¿ç•™æ–‡æœ¬",
    
    # å¤æ‚å¼•ç”¨è¿‡æ»¤
    "æ–‡æœ¬å†…å®¹ã€742442319583238â€ L62-L65ã€‘ç»§ç»­æ–‡æœ¬",
    
    # å¤šé‡è¿‡æ»¤
    "å¼€å§‹ã€ç¬¬ä¸€ä¸ªã€‘ä¸­é—´ã€ç¬¬äºŒä¸ªã€‘ç»“æŸ",
    
    # è¾¹ç•Œæƒ…å†µ
    "ã€ã€‘ç©ºæ‹¬å·æµ‹è¯•",
    "ã€åµŒå¥—ã€å†…å®¹ã€‘æµ‹è¯•ã€‘",
    
    # æ•°å­—å’Œç¬¦å·
    "åŒ…å«12345å¤§æ•°å­—å’Œâ€ â€‘ç‰¹æ®Šç¬¦å·",
]
```

### 3. é›†æˆæµ‹è¯•æµç¨‹

#### å®Œæ•´æµ‹è¯•åºåˆ—
```bash
#!/bin/bash
echo "ğŸ§ª å¼€å§‹å®Œæ•´ç³»ç»Ÿæµ‹è¯•"

# 1. ç¯å¢ƒæ£€æŸ¥
test_environment() {
    echo "æ£€æŸ¥ç¯å¢ƒå˜é‡..."
    [ -z "$OPENAI_API_KEY" ] && echo "âŒ APIå¯†é’¥ç¼ºå¤±" && return 1
    echo "âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# 2. ç»„ä»¶æµ‹è¯•
test_components() {
    echo "æµ‹è¯•å„ç»„ä»¶..."
    
    # TTSæµ‹è¯•
    ./test_tts_simple.sh || return 1
    
    # å†…å®¹è¿‡æ»¤æµ‹è¯•
    python3 test_content_filter.py || return 1
    
    echo "âœ… ç»„ä»¶æµ‹è¯•é€šè¿‡"
}

# 3. æ€§èƒ½éªŒè¯
test_performance() {
    echo "æ€§èƒ½åŸºå‡†æµ‹è¯•..."
    ./test_tts_performance.sh | grep "ç”Ÿæˆæ—¶é—´" | \
    awk -F: '{print $2}' | awk '{if($1 > 3.0) exit 1}'
    
    [ $? -eq 0 ] && echo "âœ… æ€§èƒ½è¾¾æ ‡" || echo "âŒ æ€§èƒ½ä¸è¾¾æ ‡"
}

# 4. é›†æˆæµ‹è¯•
test_integration() {
    echo "ROS2é›†æˆæµ‹è¯•..."
    
    # å¯åŠ¨èŠ‚ç‚¹
    ./start_tts_fast.sh &
    TTS_PID=$!
    sleep 3
    
    # å‘é€æµ‹è¯•æ¶ˆæ¯
    ros2 topic pub /llm_response std_msgs/String \
        "data: 'Helloã€test123ã€‘world'" --once
    
    # æ¸…ç†
    kill $TTS_PID 2>/dev/null
    echo "âœ… é›†æˆæµ‹è¯•å®Œæˆ"
}

# æ‰§è¡Œæµ‹è¯•åºåˆ—
test_environment && \
test_components && \
test_performance && \
test_integration

echo "ğŸ ç³»ç»Ÿæµ‹è¯•å®Œæˆ"
```

## âš™ï¸ é…ç½®ç®¡ç†

### ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§
```bash
# 1. ç³»ç»Ÿç¯å¢ƒå˜é‡ (æœ€é«˜ä¼˜å…ˆçº§)
export TTS_MODEL=gpt-4o-mini-tts

# 2. .env æ–‡ä»¶é…ç½®
TTS_MODEL=gpt-4o-mini-tts

# 3. ä»£ç é»˜è®¤å€¼ (æœ€ä½ä¼˜å…ˆçº§)
self.tts_model = os.environ.get("TTS_MODEL", "tts-1")
```

### åŠ¨æ€é…ç½®æ›´æ–°
```python
class ConfigManager:
    def __init__(self):
        self.config_file = ".env"
        self.load_config()
        
    def load_config(self):
        """ä».envæ–‡ä»¶åŠ è½½é…ç½®"""
        if os.path.exists(self.config_file):
            load_dotenv(self.config_file)
            
    def update_config(self, key: str, value: str):
        """åŠ¨æ€æ›´æ–°é…ç½®"""
        os.environ[key] = value
        self.save_to_file(key, value)
        
    def save_to_file(self, key: str, value: str):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        # å®ç°é…ç½®æŒä¹…åŒ–
        pass
```

## ğŸ” æ•…éšœè¯Šæ–­æŒ‡å—

### å¸¸è§é—®é¢˜æ’æŸ¥

#### 1. TTSå“åº”æ…¢
```bash
# æ£€æŸ¥æ¨¡å‹é…ç½®
echo $TTS_MODEL  # åº”è¯¥æ˜¯ gpt-4o-mini-tts

# æ£€æŸ¥æ ¼å¼é…ç½®  
echo $TTS_FORMAT  # æ¨è opus æˆ– wav

# æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
curl -w "@curl-format.txt" -o /dev/null -s "https://api.openai.com/v1/models"
```

#### 2. å†…å®¹è¿‡æ»¤å¤±æ•ˆ
```python
# æµ‹è¯•è¿‡æ»¤å™¨
def test_filter():
    test_text = "Helloã€test123ã€‘world"
    result = filter_content(test_text)
    assert "ã€" not in result, "è¿‡æ»¤å™¨å¤±æ•ˆ"
    print(f"è¿‡æ»¤æµ‹è¯•: '{test_text}' -> '{result}'")
```

#### 3. STT VADæ•æ„Ÿåº¦
```python
# è°ƒæ•´VADå‚æ•°
def tune_vad():
    # ç¯å¢ƒå™ªéŸ³å¤§æ—¶æé«˜é˜ˆå€¼
    self.rms_threshold = 1500
    
    # å®‰é™ç¯å¢ƒæ—¶é™ä½é˜ˆå€¼
    self.rms_threshold = 800
    
    # åŠ¨æ€è°ƒæ•´
    self.adaptive_threshold = True
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡
- **TTSå»¶è¿Ÿ**: < 2.5ç§’
- **å†…å­˜ä½¿ç”¨**: < 500MB
- **CPUä½¿ç”¨**: < 50%
- **é”™è¯¯ç‡**: < 1%

### ç›‘æ§å®ç°
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'tts_latency': [],
            'memory_usage': [],
            'error_count': 0
        }
    
    def record_tts_latency(self, latency: float):
        self.metrics['tts_latency'].append(latency)
        if latency > 3.0:
            self.alert_slow_tts(latency)
    
    def get_average_latency(self) -> float:
        latencies = self.metrics['tts_latency']
        return sum(latencies) / len(latencies) if latencies else 0
```

---

*æŠ€æœ¯å®ç°æ–‡æ¡£ v1.0*  
*æ›´æ–°æ—¶é—´: 2025å¹´7æœˆ27æ—¥*
