#!/usr/bin/env python3
"""
TEN VAD STT Node - ä½¿ç”¨TEN VADæ›¿ä»£RMSèƒ½é‡VAD
====================================================

è¿™ä¸ªèŠ‚ç‚¹ä½¿ç”¨TEN VAD (https://github.com/TEN-framework/ten-vad) 
æ›¿ä»£ä¼ ç»Ÿçš„RMSèƒ½é‡+é™éŸ³æ£€æµ‹VADï¼Œæä¾›æ›´ç²¾ç¡®çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹ã€‚

TEN VADä¼˜åŠ¿ï¼š
- æ¯”WebRTC VADå’ŒSilero VADæ›´ç²¾ç¡®
- ä¸“ä¸ºå¯¹è¯AIè®¾è®¡ï¼Œä½å»¶è¿Ÿ
- è½»é‡çº§ï¼Œè®¡ç®—å¤æ‚åº¦ä½
- å¿«é€Ÿæ£€æµ‹è¯­éŸ³åˆ°éè¯­éŸ³è½¬æ¢
- èƒ½è¯†åˆ«çŸ­æš‚é™éŸ³

å…³é”®å·®å¼‚å¯¹æ¯”RMS VADï¼š
- RMS VAD: åŸºäºèƒ½é‡é˜ˆå€¼ï¼Œå®¹æ˜“å—å™ªå£°å½±å“
- TEN VAD: åŸºäºæ·±åº¦å­¦ä¹ ï¼Œå¸§çº§è¯­éŸ³æ´»åŠ¨æ£€æµ‹
"""

import os
import json
import rclpy
from rclpy.node import Node
from std_msgs.msg import String, Bool
import pyaudio
import threading
import time
import difflib
import wave
import tempfile
import openai
import tenacity
from dotenv import load_dotenv
import numpy as np
import collections
import re

# TEN VAD import
try:
    import sys
    print(f"Pythonè·¯å¾„: {sys.executable}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"æ¨¡å—æœç´¢è·¯å¾„: {sys.path[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ªè·¯å¾„
    
    from ten_vad import TenVad
    TEN_VAD_AVAILABLE = True
    print("âœ… TEN VAD å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    TEN_VAD_AVAILABLE = False
    print(f"âŒ TEN VAD å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·è¿è¡Œ: pip install git+https://github.com/TEN-framework/ten-vad.git")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# -----------------------------------------------------------------------------
# Audio configuration - TEN VAD è¦æ±‚16kHzé‡‡æ ·ç‡
SAMPLE_RATE = 16000  # TEN VAD å›ºå®šè¦æ±‚16kHz
HOP_SIZE = 256  # TEN VAD é»˜è®¤å¸§å¤§å° (16ms at 16kHz)
CHANNELS = int(os.getenv("STT_CHANNELS", "1"))  # å•å£°é“
MODEL_NAME = os.getenv("OPENAI_STT_MODEL", "gpt-4o-mini-transcribe")

# TEN VADé…ç½® - é’ˆå¯¹å˜ˆæ‚ç¯å¢ƒä¼˜åŒ–
TEN_VAD_THRESHOLD = float(os.getenv("TEN_VAD_THRESHOLD", "0.8"))  # æé«˜é˜ˆå€¼åº”å¯¹å™ªéŸ³
MIN_VOICE_FRAMES = int(os.getenv("TEN_MIN_VOICE_FRAMES", "8"))  # å¢åŠ è¿ç»­å¸§è¦æ±‚
MAX_SILENCE_FRAMES = int(os.getenv("TEN_MAX_SILENCE_FRAMES", "75"))  # æœ€å¤§é™éŸ³å¸§æ•°(çº¦1.2ç§’)
BUFFER_HISTORY_FRAMES = int(os.getenv("TEN_BUFFER_HISTORY_FRAMES", "30"))  # å‰ç¼“å†²å¸§æ•°

# éŸ³é¢‘è´¨é‡è¿‡æ»¤ - åŠ å¼ºå™ªéŸ³è¿‡æ»¤
MIN_AUDIO_ENERGY = float(os.getenv("TEN_MIN_AUDIO_ENERGY", "200"))  # æé«˜æœ€å°èƒ½é‡è¦æ±‚
MIN_SPEECH_DURATION_MS = float(os.getenv("TEN_MIN_SPEECH_DURATION_MS", "500"))  # å¢åŠ æœ€çŸ­è¯­éŸ³æ—¶é•¿
NOISE_FLOOR_ADAPTATION = float(os.getenv("TEN_NOISE_FLOOR_ADAPTATION", "0.3"))  # å™ªéŸ³åº•å™ªè‡ªé€‚åº”

# å”¤é†’è¯é…ç½®
WAKE_WORD_SIMILARITY = float(os.getenv("WAKE_WORD_SIMILARITY_THRESHOLD", "0.86"))

# TTSé—¨æ§é…ç½®
RESUME_HANGOVER_SEC = float(os.getenv("STT_RESUME_HANGOVER_SEC", "0.8"))
ALLOW_BARGE_IN = os.getenv("STT_ALLOW_BARGE_IN", "false").lower() == "true"
TTS_ECHO_FILTER_DURATION = float(os.getenv("TTS_ECHO_FILTER_DURATION", "3.0"))

# æ€§èƒ½ç›‘æ§
PERFORMANCE_MONITOR_INTERVAL = float(os.getenv("PERFORMANCE_MONITOR_INTERVAL", "30"))
DEBUG_MODE = os.getenv("TEN_VAD_DEBUG_MODE", "false").lower() == "true"

# è®¾å¤‡é€‰æ‹©
INPUT_DEVICE_NAME = os.getenv("STT_INPUT_DEVICE_NAME", "").strip()
INPUT_DEVICE_INDEX = os.getenv("STT_INPUT_DEVICE_INDEX", "").strip()
# -----------------------------------------------------------------------------

class TenVADSTTNode(Node):
    def __init__(self):
        super().__init__('ten_vad_stt_node')
        
        # æ£€æŸ¥TEN VADå¯ç”¨æ€§
        if not TEN_VAD_AVAILABLE:
            raise RuntimeError("TEN VAD æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install git+https://github.com/TEN-framework/ten-vad.git")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        
        self.openai_client = openai.OpenAI(api_key=api_key)
        
        # ROS2 å‘å¸ƒè€…å’Œè®¢é˜…è€…
        self.publisher_ = self.create_publisher(String, 'speech_text', 10)
        self.tts_status_sub = self.create_subscription(Bool, 'tts_status', self.tts_status_callback, 10)
        self.tts_text_sub = self.create_subscription(String, 'llm_response', self.llm_response_callback, 10)
        
        # åˆå§‹åŒ–TEN VAD
        try:
            self.ten_vad = TenVad(hop_size=HOP_SIZE, threshold=TEN_VAD_THRESHOLD)
            self.get_logger().info(f"TEN VAD åˆå§‹åŒ–æˆåŠŸ: hop_size={HOP_SIZE}, threshold={TEN_VAD_THRESHOLD}")
            
            # è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†
            self.adaptive_threshold = TEN_VAD_THRESHOLD
            self.false_positive_count = 0
            self.successful_detections = 0
            self.threshold_adjustment_window = 50  # æ¯50æ¬¡æ£€æµ‹è°ƒæ•´ä¸€æ¬¡
            
        except Exception as e:
            self.get_logger().error(f"TEN VAD åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # éŸ³é¢‘è®¾å¤‡è®¾ç½®
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self._setup_audio_input()
        
        # å”¤é†’è¯é…ç½®
        self.wake_words = ["nUWAy", "new way", "nu way", "en you way", "nuway", "n u way"]
        self.wake_regex = re.compile(r'^\s*(n\s*u\s*way|new\s*way|nu\s*way|en\s*you\s*way|nuway)\b', re.I)
        
        # VADçŠ¶æ€ç®¡ç†
        self.vad_state = "silence"  # "silence", "speech", "processing"
        self.speech_buffer = collections.deque(maxlen=BUFFER_HISTORY_FRAMES)
        self.current_speech_frames = []
        self.voice_frame_count = 0
        self.silence_frame_count = 0
        
        # å™ªéŸ³è‡ªé€‚åº”ç®¡ç†
        self.noise_floor_history = collections.deque(maxlen=100)  # ä¿å­˜æœ€è¿‘100å¸§çš„èƒ½é‡
        self.current_noise_floor = MIN_AUDIO_ENERGY
        self.noise_update_counter = 0
        
        # ä¼˜åŒ–ï¼šé¢„åˆ†é…éŸ³é¢‘ç¼“å†²åŒºï¼Œé¿å…é¢‘ç¹å†…å­˜åˆ†é…
        self.max_speech_frames = int(SAMPLE_RATE * 10 / HOP_SIZE)  # æœ€å¤š10ç§’è¯­éŸ³
        self.audio_buffer_pool = []
        
        # TTSé—¨æ§çŠ¶æ€
        self.tts_playing = False
        self.resume_at = 0.0
        self._should_reset = False
        
        # TTSå›æ”¾è¿‡æ»¤
        self._tts_recent_text = ""
        self._tts_recent_expiry = 0.0
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            'total_frames_processed': 0,
            'speech_frames_detected': 0,
            'transcription_attempts': 0,
            'successful_transcriptions': 0,
            'average_processing_time': 0.0,
            'last_reset_time': time.time()
        }
        
        # å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹
        self.audio_thread = threading.Thread(target=self._audio_processing_thread, daemon=True)
        self.audio_thread.start()
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§çº¿ç¨‹
        self.stats_thread = threading.Thread(target=self._performance_monitoring_thread, daemon=True)
        self.stats_thread.start()
        
        self.get_logger().info(
            f"TEN VAD STT èŠ‚ç‚¹å¯åŠ¨å®Œæˆï¼š"
            f" é‡‡æ ·ç‡={SAMPLE_RATE}Hz, å¸§å¤§å°={HOP_SIZE}, "
            f"æœ€å°è¯­éŸ³å¸§={MIN_VOICE_FRAMES}, æœ€å¤§é™éŸ³å¸§={MAX_SILENCE_FRAMES}"
        )

    def _setup_audio_input(self):
        """è®¾ç½®éŸ³é¢‘è¾“å…¥è®¾å¤‡"""
        chosen_index = None
        
        try:
            device_count = self.audio.get_device_count()
            self.get_logger().info(f"æ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡æ•°é‡: {device_count}")
            
            for i in range(device_count):
                info = self.audio.get_device_info_by_index(i)
                name = info.get('name', 'unknown')
                max_in = int(info.get('maxInputChannels', 0))
                rate = int(info.get('defaultSampleRate', 0))
                self.get_logger().info(f"è®¾å¤‡[{i}]: '{name}', è¾“å…¥é€šé“={max_in}, é»˜è®¤é‡‡æ ·ç‡={rate}")
            
            # è®¾å¤‡é€‰æ‹©é€»è¾‘
            if INPUT_DEVICE_INDEX.isdigit():
                chosen_index = int(INPUT_DEVICE_INDEX)
            elif INPUT_DEVICE_NAME:
                needle = INPUT_DEVICE_NAME.lower()
                for i in range(device_count):
                    info = self.audio.get_device_info_by_index(i)
                    if needle in info.get('name', '').lower() and int(info.get('maxInputChannels', 0)) >= CHANNELS:
                        chosen_index = i
                        break
                        
        except Exception as e:
            self.get_logger().warning(f"éŸ³é¢‘è®¾å¤‡æšä¸¾å¤±è´¥: {e}")
            chosen_index = None

        # åˆå§‹åŒ–éŸ³é¢‘æµ
        try:
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=CHANNELS,
                rate=SAMPLE_RATE,
                input=True,
                frames_per_buffer=HOP_SIZE,
                input_device_index=chosen_index if chosen_index is not None else None,
            )
            
            dev_desc = f"è®¾å¤‡ç´¢å¼•={chosen_index}" if chosen_index is not None else "é»˜è®¤è®¾å¤‡"
            self.get_logger().info(f"éŸ³é¢‘è¾“å…¥å·²å¼€å¯: {dev_desc}, é‡‡æ ·ç‡={SAMPLE_RATE}, å¸§å¤§å°={HOP_SIZE}")
            
        except Exception as e:
            self.get_logger().error(
                f"éŸ³é¢‘è¾“å…¥å¼€å¯å¤±è´¥: {e}. è¿™åœ¨å®¹å™¨ç¯å¢ƒä¸­æ˜¯æ­£å¸¸çš„ã€‚"
                f"åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¯·æ£€æŸ¥ STT_INPUT_DEVICE_NAME æˆ– STT_INPUT_DEVICE_INDEX è®¾ç½®ï¼Œ"
                f"ç¡®ä¿è®¾å¤‡æ”¯æŒ 16kHz é‡‡æ ·ç‡ã€‚"
            )
            
            # åœ¨å®¹å™¨ç¯å¢ƒä¸­åˆ›å»ºæ¨¡æ‹Ÿæµç”¨äºæµ‹è¯•
            self.get_logger().warning("âš ï¸  ä½¿ç”¨æ¨¡æ‹ŸéŸ³é¢‘æµè¿›è¡Œæµ‹è¯•ï¼ˆå®¹å™¨ç¯å¢ƒï¼‰")
            self.stream = None  # æ ‡è®°ä¸ºæ¨¡æ‹Ÿæ¨¡å¼
            return

    def _to_mono(self, audio_bytes: bytes) -> bytes:
        """å°†å¤šå£°é“éŸ³é¢‘è½¬æ¢ä¸ºå•å£°é“"""
        if CHANNELS == 1:
            return audio_bytes
        
        try:
            pcm = np.frombuffer(audio_bytes, dtype=np.int16)
            if pcm.size % CHANNELS != 0:
                pcm = pcm[:(pcm.size // CHANNELS) * CHANNELS]
            frames = pcm.reshape(-1, CHANNELS).astype(np.int32)
            mono = frames.mean(axis=1).astype(np.int16)
            return mono.tobytes()
        except Exception:
            return audio_bytes

    def _audio_processing_thread(self):
        """éŸ³é¢‘å¤„ç†çº¿ç¨‹ - ä½¿ç”¨TEN VADè¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹"""
        while rclpy.ok():
            try:
                # è¯»å–éŸ³é¢‘æ•°æ®
                raw_audio = self.stream.read(HOP_SIZE, exception_on_overflow=False)
                audio_data = self._to_mono(raw_audio)
                
                current_time = time.time()
                
                # TTSé—¨æ§æ£€æŸ¥
                gated = self.tts_playing or (self.resume_at and current_time < self.resume_at)
                
                # é—¨æ§æœŸé—´é‡ç½®çŠ¶æ€
                if gated and self._should_reset:
                    self.speech_buffer.clear()
                    self.current_speech_frames.clear()
                    self.voice_frame_count = 0
                    self.silence_frame_count = 0
                    self.vad_state = "silence"
                    self._should_reset = False
                    self.get_logger().debug("TTSæœŸé—´é‡ç½®VADçŠ¶æ€")
                
                # å¦‚æœé—¨æ§ä¸”ä¸å…è®¸æ‰“æ–­ï¼Œè·³è¿‡å¤„ç†
                if gated and not ALLOW_BARGE_IN:
                    time.sleep(0.01)
                    continue
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡ŒTEN VADå¤„ç†
                audio_np = np.frombuffer(audio_data, dtype=np.int16)
                
                # ä½¿ç”¨TEN VADå¤„ç†éŸ³é¢‘å¸§
                voice_probability, voice_flag = self.ten_vad.process(audio_np)
                
                # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                self.performance_stats['total_frames_processed'] += 1
                if voice_flag == 1:
                    self.performance_stats['speech_frames_detected'] += 1
                
                # VADçŠ¶æ€æœºå¤„ç†
                self._process_vad_result(voice_probability, voice_flag, audio_data, gated)
                
            except Exception as e:
                self.get_logger().error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                time.sleep(0.05)

    def _process_vad_result(self, voice_prob: float, voice_flag: int, audio_data: bytes, gated: bool):
        """å¤„ç†TEN VADç»“æœå¹¶ç®¡ç†è¯­éŸ³çŠ¶æ€"""
        
        # æ›´æ–°å™ªéŸ³åº•å™ªä¼°è®¡ï¼ˆä»…åœ¨é™éŸ³æœŸé—´ï¼‰
        if self.vad_state == "silence" and voice_flag == 0:
            self._update_noise_floor(audio_data)
        
        # ä½¿ç”¨è‡ªé€‚åº”èƒ½é‡é˜ˆå€¼è¿›è¡Œé¢å¤–è¿‡æ»¤
        adaptive_energy_threshold = max(self.current_noise_floor * 2.0, MIN_AUDIO_ENERGY)
        
        if self.vad_state == "silence":
            # å§‹ç»ˆç»´æŠ¤å†å²ç¼“å†²åŒº
            self.speech_buffer.append(audio_data)
            
            if voice_flag == 1:  # TEN VADæ£€æµ‹åˆ°è¯­éŸ³
                # é¢å¤–çš„èƒ½é‡æ£€æŸ¥ï¼šç¡®ä¿éŸ³é¢‘èƒ½é‡è¶³å¤Ÿé«˜
                try:
                    audio_np = np.frombuffer(audio_data, dtype=np.int16)
                    current_energy = np.sqrt(np.mean(audio_np.astype(np.float32) ** 2))
                    
                    # åŒæ—¶æ»¡è¶³TEN VADå’Œèƒ½é‡æ¡ä»¶
                    if current_energy >= adaptive_energy_threshold:
                        self.voice_frame_count += 1
                        if self.voice_frame_count == 1:
                            self.get_logger().debug(f"æ£€æµ‹åˆ°æ½œåœ¨è¯­éŸ³å¼€å§‹ (æ¦‚ç‡: {voice_prob:.3f}, èƒ½é‡: {current_energy:.1f})")
                    else:
                        # èƒ½é‡ä¸è¶³ï¼Œé‡ç½®è®¡æ•°
                        self.voice_frame_count = 0
                        if DEBUG_MODE:
                            self.get_logger().debug(f"èƒ½é‡ä¸è¶³ï¼Œå¿½ç•¥VADæ£€æµ‹ (èƒ½é‡: {current_energy:.1f} < {adaptive_energy_threshold:.1f})")
                        return
                        
                except Exception:
                    # å¦‚æœèƒ½é‡è®¡ç®—å¤±è´¥ï¼Œä»ç„¶ä½¿ç”¨TEN VADç»“æœ
                    self.voice_frame_count += 1
                    if self.voice_frame_count == 1:
                        self.get_logger().debug(f"æ£€æµ‹åˆ°æ½œåœ¨è¯­éŸ³å¼€å§‹ (æ¦‚ç‡: {voice_prob:.3f})")
                
                # è¿ç»­è¯­éŸ³å¸§æ•°è¾¾åˆ°é˜ˆå€¼ï¼Œç¡®è®¤è¯­éŸ³å¼€å§‹
                if self.voice_frame_count >= MIN_VOICE_FRAMES:
                    self.vad_state = "speech"
                    self.voice_frame_count = 0
                    self.silence_frame_count = 0
                    
                    # å°†å†å²ç¼“å†²åŒºæ·»åŠ åˆ°å½“å‰è¯­éŸ³
                    self.current_speech_frames = list(self.speech_buffer)
                    
                    # æ‰“å°è¯­éŸ³å¼€å§‹æç¤º
                    print(f"\nğŸ¤ å¼€å§‹å½•éŸ³... (è¯­éŸ³æ¦‚ç‡: {voice_prob:.3f})")
                    
                    self.get_logger().info(f"ğŸ¤ TEN VAD: è¯­éŸ³å¼€å§‹ (æ¦‚ç‡: {voice_prob:.3f})")
            else:
                self.voice_frame_count = 0
                
        elif self.vad_state == "speech":
            # æ·»åŠ éŸ³é¢‘å¸§åˆ°å½“å‰è¯­éŸ³
            self.current_speech_frames.append(audio_data)
            
            if voice_flag == 0:  # æ£€æµ‹åˆ°é™éŸ³
                self.silence_frame_count += 1
                silence_duration_ms = self.silence_frame_count * 16  # æ¯å¸§16ms
                
                # é™éŸ³æŒç»­æ—¶é—´è¶…è¿‡é˜ˆå€¼ï¼Œç¡®è®¤è¯­éŸ³ç»“æŸ
                if self.silence_frame_count >= MAX_SILENCE_FRAMES:
                    self.vad_state = "processing"
                    speech_duration_ms = len(self.current_speech_frames) * 16
                    
                    # æ‰“å°è¯­éŸ³ç»“æŸæç¤º
                    print(f"ğŸ”‡ å½•éŸ³ç»“æŸï¼Œæ­£åœ¨è¯†åˆ«... (æ—¶é•¿: {speech_duration_ms}ms)")
                    
                    self.get_logger().info(f"ğŸ”‡ TEN VAD: è¯­éŸ³ç»“æŸ (æ—¶é•¿: {speech_duration_ms}ms)")
                    
                    # å¼‚æ­¥å¤„ç†è¯­éŸ³
                    if len(self.current_speech_frames) > 10:  # æœ€å°‘å¤„ç†çº¦160msçš„è¯­éŸ³
                        speech_data = b''.join(self.current_speech_frames)
                        processing_thread = threading.Thread(
                            target=self._process_speech_chunk,
                            args=(speech_data, gated),
                            daemon=True
                        )
                        processing_thread.start()
                    
                    # é‡ç½®çŠ¶æ€
                    self.current_speech_frames.clear()
                    self.silence_frame_count = 0
                    self.vad_state = "silence"
            else:
                self.silence_frame_count = 0  # é‡ç½®é™éŸ³è®¡æ•°

    def _update_noise_floor(self, audio_data: bytes):
        """æ›´æ–°å™ªéŸ³åº•å™ªä¼°è®¡"""
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            current_energy = np.sqrt(np.mean(audio_np.astype(np.float32) ** 2))
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.noise_floor_history.append(current_energy)
            self.noise_update_counter += 1
            
            # æ¯50å¸§æ›´æ–°ä¸€æ¬¡å™ªéŸ³åº•å™ªä¼°è®¡
            if self.noise_update_counter >= 50 and len(self.noise_floor_history) >= 20:
                # ä½¿ç”¨ç¬¬10ç™¾åˆ†ä½æ•°ä½œä¸ºå™ªéŸ³åº•å™ª
                self.current_noise_floor = np.percentile(list(self.noise_floor_history), 10)
                self.noise_update_counter = 0
                
                if DEBUG_MODE:
                    self.get_logger().debug(f"æ›´æ–°å™ªéŸ³åº•å™ª: {self.current_noise_floor:.1f}")
                    
        except Exception as e:
            if DEBUG_MODE:
                self.get_logger().debug(f"å™ªéŸ³åº•å™ªæ›´æ–°å¤±è´¥: {e}")

    def _process_speech_chunk(self, speech_data: bytes, gated: bool = False):
        """å¤„ç†æ£€æµ‹åˆ°çš„è¯­éŸ³ç‰‡æ®µ"""
        start_time = time.time()
        
        # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        self.performance_stats['transcription_attempts'] += 1
        
        # TTSæœŸé—´ä¸”ä¸å…è®¸æ‰“æ–­
        if gated and not ALLOW_BARGE_IN:
            self.get_logger().debug("TTSæœŸé—´è·³è¿‡è¯­éŸ³å¤„ç†")
            return

        # æ£€æŸ¥è¯­éŸ³é•¿åº¦å’Œè´¨é‡
        speech_duration_ms = len(speech_data) / (SAMPLE_RATE * 2) * 1000
        if speech_duration_ms < MIN_SPEECH_DURATION_MS:
            self.get_logger().debug(f"è¯­éŸ³ç‰‡æ®µè¿‡çŸ­ ({speech_duration_ms:.0f}ms < {MIN_SPEECH_DURATION_MS}ms)ï¼Œå¿½ç•¥")
            return
        
        # ç®€å•çš„éŸ³é¢‘è´¨é‡æ£€æŸ¥ï¼ˆRMSèƒ½é‡ï¼‰
        try:
            audio_np = np.frombuffer(speech_data, dtype=np.int16)
            rms_energy = np.sqrt(np.mean(audio_np.astype(np.float32) ** 2))
            if rms_energy < MIN_AUDIO_ENERGY:
                self.get_logger().debug(f"éŸ³é¢‘èƒ½é‡è¿‡ä½ (RMS: {rms_energy:.1f} < {MIN_AUDIO_ENERGY})ï¼Œè·³è¿‡")
                return
            
            if DEBUG_MODE:
                self.get_logger().info(f"ğŸ”Š å¤„ç†è¯­éŸ³: {speech_duration_ms:.0f}ms, RMS: {rms_energy:.1f}")
                
        except Exception:
            pass

        try:
            # åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp:
                self._write_wav(tmp.name, speech_data)
                
                # æ‰“å°æ­£åœ¨è½¬å½•æç¤º
                print("ğŸ”„ æ­£åœ¨è½¬å½•è¯­éŸ³...")
                
                transcript = self._transcribe_file(tmp.name)
                
                if transcript:
                    self.performance_stats['successful_transcriptions'] += 1
                    self._process_recognized_text(transcript)
                
                # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
                processing_time = time.time() - start_time
                current_avg = self.performance_stats['average_processing_time']
                total_attempts = self.performance_stats['transcription_attempts']
                self.performance_stats['average_processing_time'] = (
                    (current_avg * (total_attempts - 1) + processing_time) / total_attempts
                )
                
        except Exception as e:
            self.get_logger().error(f"è¯­éŸ³å¤„ç†é”™è¯¯: {e}")

    def _write_wav(self, path: str, pcm_bytes: bytes):
        """å†™å…¥WAVæ–‡ä»¶"""
        with wave.open(path, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(pcm_bytes)

    @tenacity.retry(stop=tenacity.stop_after_attempt(3),
                    wait=tenacity.wait_exponential(multiplier=1, min=1, max=10))
    def _transcribe_file(self, fname: str) -> str:
        """ä½¿ç”¨OpenAI Whisperè½¬å½•éŸ³é¢‘"""
        try:
            with open(fname, "rb") as f:
                response = self.openai_client.audio.transcriptions.create(
                    model=MODEL_NAME,
                    file=f,
                    temperature=0,
                    response_format="text"
                )
            return response.strip() if isinstance(response, str) else response.strip()
        except Exception as e:
            self.get_logger().error(f"OpenAI API è°ƒç”¨å¤±è´¥: {e}")
            return ""

    def _process_recognized_text(self, text: str):
        """å¤„ç†è¯†åˆ«çš„æ–‡æœ¬ï¼Œæ£€æŸ¥å”¤é†’è¯"""
        if not text:
            return

        # TTSå›æ”¾è¿‡æ»¤
        now = time.time()
        if self._tts_recent_text and now < self._tts_recent_expiry:
            norm_ref = self._normalize_text(self._tts_recent_text)
            norm_txt = self._normalize_text(text)
            words = norm_txt.split()
            prefix = ' '.join(words[:6])
            if prefix and prefix in norm_ref:
                self.get_logger().info("ä¸¢å¼ƒTTSå›æ”¾æ–‡æœ¬")
                return

        lower_text = text.lower().strip()

        # ä¸¥æ ¼æ­£åˆ™åŒ¹é…å”¤é†’è¯
        if self.wake_regex.search(lower_text):
            print("\nğŸ”¥ æ£€æµ‹åˆ°å”¤é†’è¯ (æ­£åˆ™åŒ¹é…)!")
            self._publish_transcript(text)
            self.get_logger().info(f"ğŸ”¥ å”¤é†’è¯æ£€æµ‹æˆåŠŸ (æ­£åˆ™): {text}")
            return

        # æ¨¡ç³ŠåŒ¹é…å¥é¦–å”¤é†’è¯
        for wake_word in self.wake_words:
            n = len(wake_word)
            candidate = lower_text[:max(n + 2, n)]
            ratio = difflib.SequenceMatcher(None, candidate, wake_word).ratio()
            if ratio >= WAKE_WORD_SIMILARITY:
                print(f"\nğŸ”¥ æ£€æµ‹åˆ°å”¤é†’è¯ (æ¨¡ç³ŠåŒ¹é… {ratio:.2f})!")
                self._publish_transcript(text)
                self.get_logger().info(f"ğŸ”¥ å”¤é†’è¯æ£€æµ‹æˆåŠŸ (æ¨¡ç³Š {ratio:.2f}): {text}")
                return

        if DEBUG_MODE:
            self.get_logger().info(f"æœªæ£€æµ‹åˆ°å”¤é†’è¯: {text}")

    def _publish_transcript(self, transcript: str):
        """å‘å¸ƒè½¬å½•ç»“æœåˆ°ROSè¯é¢˜"""
        
        # æ‰“å°è¯†åˆ«åˆ°çš„è¯­éŸ³
        print("\n" + "="*60)
        print("ğŸ¤ ç”¨æˆ·è¯­éŸ³è¯†åˆ«ç»“æœ:")
        print("-"*60)
        print(f"'{transcript}'")
        print("="*60)
        
        msg = String()
        msg.data = transcript
        self.publisher_.publish(msg)

    def _normalize_text(self, text: str) -> str:
        """æ–‡æœ¬è§„èŒƒåŒ–"""
        text = text.lower().strip()
        text = re.sub(r'[^a-z0-9\s]+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text

    def _performance_monitoring_thread(self):
        """æ€§èƒ½ç›‘æ§çº¿ç¨‹ï¼Œæ¯30ç§’è¾“å‡ºç»Ÿè®¡ä¿¡æ¯"""
        if PERFORMANCE_MONITOR_INTERVAL <= 0:
            return  # ç¦ç”¨æ€§èƒ½ç›‘æ§
            
        while rclpy.ok():
            try:
                time.sleep(PERFORMANCE_MONITOR_INTERVAL)
                
                stats = self.performance_stats
                current_time = time.time()
                elapsed = current_time - stats['last_reset_time']
                
                if stats['total_frames_processed'] > 0:
                    speech_ratio = stats['speech_frames_detected'] / stats['total_frames_processed']
                    success_ratio = (stats['successful_transcriptions'] / max(1, stats['transcription_attempts']))
                    
                    self.get_logger().info(
                        f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡ ({elapsed:.1f}s): "
                        f"è¯­éŸ³å¸§ç‡={speech_ratio:.1%}, "
                        f"è½¬å½•æˆåŠŸç‡={success_ratio:.1%}, "
                        f"å¹³å‡å¤„ç†æ—¶é—´={stats['average_processing_time']:.3f}s, "
                        f"æ€»å¤„ç†å¸§={stats['total_frames_processed']}"
                    )
                
            except Exception as e:
                self.get_logger().warning(f"æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")

    def tts_status_callback(self, msg: Bool):
        """TTSçŠ¶æ€å›è°ƒ"""
        if msg.data:
            self.get_logger().info("TTSæ’­æ”¾å¼€å§‹ï¼Œå¯ç”¨é—¨æ§")
            self.tts_playing = True
            self.resume_at = 0.0
            self._should_reset = True
        else:
            self.get_logger().info(f"TTSæ’­æ”¾ç»“æŸï¼Œ{int(RESUME_HANGOVER_SEC*1000)}msåæ¢å¤")
            self.tts_playing = False
            self.resume_at = time.time() + RESUME_HANGOVER_SEC
            self._should_reset = True

    def llm_response_callback(self, msg: String):
        """ç¼“å­˜LLMå“åº”æ–‡æœ¬ç”¨äºå›æ”¾è¿‡æ»¤"""
        text = (msg.data or '').strip()
        if not text:
            return
        
        if self.tts_playing or (self.resume_at and time.time() < self.resume_at + 1.0):
            combined = (self._tts_recent_text + ' ' + text).strip()
            self._tts_recent_text = combined[-1000:]
            self._tts_recent_expiry = time.time() + TTS_ECHO_FILTER_DURATION

    def destroy_node(self):
        """æ¸…ç†èµ„æº"""
        self.get_logger().info("å…³é—­TEN VAD STTèŠ‚ç‚¹...")
        
        if hasattr(self, 'stream') and self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        if hasattr(self, 'audio'):
            self.audio.terminate()
        
        # æ¸…ç†TEN VADèµ„æº
        if hasattr(self, 'ten_vad'):
            del self.ten_vad
        
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = TenVADSTTNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        print(f"èŠ‚ç‚¹å¯åŠ¨å¤±è´¥: {e}")
    finally:
        if 'node' in locals():
            node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
