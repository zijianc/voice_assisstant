import os
import json
import rclpy
from rclpy.node import Node
from std_msgs.msg import String, Bool
import pyaudio
import queue
import threading
import time
import difflib
import wave
import tempfile
import openai
import tenacity
from dotenv import load_dotenv
import numpy as np
import collections
import re

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# -----------------------------------------------------------------------------
# Audio configuration
# å…è®¸é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼Œä¾¿äºé€‚é… USB ä¼šè®®éº¦å…‹é£
SAMPLE_RATE = int(os.getenv("STT_SAMPLE_RATE", os.getenv("OPENAI_STT_SAMPLE_RATE", "24000")))
# å¦‚æœè¿æ¥ 48k è®¾å¤‡ï¼Œå»ºè®® CHUNK_SIZE=960 (çº¦20ms)ï¼›å¦åˆ™ä¿æŒ 1024 é»˜è®¤
_default_chunk = "960" if SAMPLE_RATE == 48000 else "1024"
CHUNK_SIZE = int(os.getenv("STT_CHUNK_SIZE", _default_chunk))
CHANNELS = int(os.getenv("STT_CHANNELS", "1"))  # ä¼šè®®éº¦å¯èƒ½æ˜¯åŒå£°é“ï¼›ä¸‹æ–¹åšå•å£°é“ä¸‹æ··
#MODEL_NAME = os.getenv("OPENAI_STT_MODEL", "whisper-1")
MODEL_NAME = os.getenv("OPENAI_STT_MODEL", "gpt-4o-mini-transcribe")

# VAD é…ç½® - è°ƒæ•´è¿™äº›å‚æ•°æ¥æ”¹å–„å”¤é†’è¯æ£€æµ‹ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
VAD_THRESHOLD = float(os.getenv("STT_VAD_THRESHOLD", "0.015"))
SILENCE_DURATION = float(os.getenv("STT_SILENCE_DURATION", "2.0"))
MIN_SPEECH_DURATION = float(os.getenv("STT_MIN_SPEECH_DURATION", "0.2"))
BUFFER_HISTORY = float(os.getenv("STT_BUFFER_HISTORY", "1.5"))

# æ–°å¢ï¼šé—¨æ§/é˜ˆå€¼/ç›¸ä¼¼åº¦/å…è®¸æ‰“æ–­é…ç½®
RESUME_HANGOVER_SEC = float(os.getenv("STT_RESUME_HANGOVER_SEC", "0.8"))
TTS_VAD_THRESHOLD_BOOST = float(os.getenv("TTS_VAD_THRESHOLD_BOOST", "2.0"))
SNR_GATE = float(os.getenv("STT_WAKEWORD_SNR_GATE", "1.8"))  # ç‰‡æ®µRMS/èƒŒæ™¯èƒ½é‡ æ¯”å€¼é—¨é™
ALLOW_BARGE_IN = os.getenv("STT_ALLOW_BARGE_IN", "false").lower() == "true"
# å¯é€‰ï¼šé€‰æ‹©æŒ‡å®šè¾“å…¥è®¾å¤‡ï¼ˆåç§°åŒ…å«åŒ¹é… æˆ– è®¾å¤‡ç´¢å¼•ï¼‰
INPUT_DEVICE_NAME = os.getenv("STT_INPUT_DEVICE_NAME", "").strip()
INPUT_DEVICE_INDEX = os.getenv("STT_INPUT_DEVICE_INDEX", "").strip()
# -----------------------------------------------------------------------------

class OpenAISTTNodeWithVAD(Node):
    def __init__(self):
        super().__init__('openai_stt_node_with_vad')
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        
        self.openai_client = openai.OpenAI(api_key=api_key)
        
        # åˆ›å»ºå‘å¸ƒè€…ï¼Œå‘å¸ƒè¯†åˆ«ç»“æœåˆ°è¯é¢˜ 'speech_text'
        self.publisher_ = self.create_publisher(String, 'speech_text', 10)
        # è®¢é˜… TTS çŠ¶æ€æ¶ˆæ¯
        self.tts_status_sub = self.create_subscription(Bool, 'tts_status', self.tts_status_callback, 10)
        # æ–°å¢ï¼šè®¢é˜… llm_response åšè‡ªå›æ”¾æ–‡æœ¬è¿‡æ»¤å…œåº•
        self.tts_text_sub = self.create_subscription(String, 'llm_response', self.llm_response_callback, 10)
        self.listening = True  # ä¸å†ç”¨å®ƒåšé—¨æ§ï¼Œä»…ä¿æŒçº¿ç¨‹æ´»è·ƒ

        # å…è®¸ç”¨æˆ·è°ƒæ•´VADå‚æ•°ï¼ˆä»æ”¯æŒé€šè¿‡ ROS å‚æ•°åŠ¨æ€è®¾ç½®ï¼‰
        self.declare_parameter('vad_threshold', VAD_THRESHOLD)
        self.declare_parameter('silence_duration', SILENCE_DURATION)
        self.declare_parameter('min_speech_duration', MIN_SPEECH_DURATION)
        self.declare_parameter('buffer_history', BUFFER_HISTORY)
        
        # è·å–å‚æ•°
        self.vad_threshold = self.get_parameter('vad_threshold').value
        self.silence_duration = self.get_parameter('silence_duration').value
        self.min_speech_duration = self.get_parameter('min_speech_duration').value
        self.buffer_history = self.get_parameter('buffer_history').value

        # è®¾å¤‡é€‰æ‹©ä¸æ—¥å¿—
        self.audio = pyaudio.PyAudio()
        chosen_index = None
        try:
            device_count = self.audio.get_device_count()
            self.get_logger().info(f"æ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡æ•°é‡: {device_count}")
            for i in range(device_count):
                info = self.audio.get_device_info_by_index(i)
                name = info.get('name', 'unknown')
                host_api = info.get('hostApi')
                max_in = int(info.get('maxInputChannels', 0))
                rate = int(info.get('defaultSampleRate', 0))
                self.get_logger().info(f"è¾“å…¥è®¾å¤‡[{i}]: name='{name}', maxIn={max_in}, defaultSR={rate}")
            # é€‰æ‹©é€»è¾‘ï¼šä¼˜å…ˆç´¢å¼•ï¼Œå…¶æ¬¡åç§°åŒ…å«
            if INPUT_DEVICE_INDEX.isdigit():
                chosen_index = int(INPUT_DEVICE_INDEX)
            elif INPUT_DEVICE_NAME:
                needle = INPUT_DEVICE_NAME.lower()
                for i in range(device_count):
                    info = self.audio.get_device_info_by_index(i)
                    if needle in info.get('name', '').lower() and int(info.get('maxInputChannels', 0)) >= CHANNELS:
                        chosen_index = i
                        break
        except Exception as e:
            self.get_logger().warning(f"éŸ³é¢‘è®¾å¤‡æšä¸¾å¤±è´¥: {e}")
            chosen_index = None

        # åˆå§‹åŒ–éŸ³é¢‘è¾“å…¥ï¼ˆæ”¯æŒå¤šå£°é“ï¼Œéšåç»Ÿä¸€ä¸‹æ··ä¸ºå•å£°é“ï¼‰
        self.channels = CHANNELS
        self.sample_rate = SAMPLE_RATE
        self.chunk_size = CHUNK_SIZE
        try:
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                input_device_index=chosen_index if chosen_index is not None else None,
            )
            dev_desc = f"index={chosen_index}" if chosen_index is not None else "default"
            self.get_logger().info(
                f"å¼€å§‹ç›‘å¬éº¦å…‹é£ (VAD), device={dev_desc}, ch={self.channels}, SR={self.sample_rate}, chunk={self.chunk_size}"
            )
        except Exception as e:
            self.get_logger().error(
                f"æ‰“å¼€éŸ³é¢‘è¾“å…¥å¤±è´¥: {e}. è¯·å°è¯•è®¾ç½® STT_INPUT_DEVICE_NAME æˆ– STT_INPUT_DEVICE_INDEXï¼Œ"
                f"å¹¶ç¡®ä¿ STT_SAMPLE_RATE/ STT_CHANNELS ä¸è®¾å¤‡æ”¯æŒçš„å‚æ•°åŒ¹é…ï¼ˆå¸¸è§ SR: 16000/24000/48000ï¼‰ã€‚"
            )
            raise
        self.stream.start_stream()

        # è®¾ç½®å”¤é†’è¯ä¸ä¸¥æ ¼æ­£åˆ™ï¼ˆä»…å¥é¦–ã€è¯è¾¹ç•Œï¼‰
        self.wake_words = ["hi captain", "hey captain", "hello captain"]
        self.wake_regex = re.compile(r'^\s*(hi|hey|hello)\W+captain\b', re.I)

        # VAD ç›¸å…³å˜é‡
        self.vad_state = "silence"  # "silence", "speech", "processing"
        self.speech_buffer = collections.deque(maxlen=int(self.sample_rate * self.buffer_history / self.chunk_size))
        self.current_speech = bytearray()
        self.silence_counter = 0
        self.speech_counter = 0
        self.last_speech_time = 0
        
        # èƒ½é‡å†å²ï¼Œç”¨äºåŠ¨æ€é˜ˆå€¼è°ƒæ•´
        self.energy_history = collections.deque(maxlen=50)  # å­˜å‚¨æœ€è¿‘50ä¸ªèƒ½é‡å€¼
        self.background_energy = 0.01  # åˆå§‹èƒŒæ™¯èƒ½é‡ä¼°è®¡å€¼
        self.tts_threshold_boost = TTS_VAD_THRESHOLD_BOOST

        # æ–°å¢ï¼šTTSé—¨æ§çŠ¶æ€
        self.tts_playing = False
        self.resume_at = 0.0
        self._should_drain = False
        self._freeze_noise = False
        # æœ€è¿‘TTSæ–‡æœ¬ç¼“å­˜
        self._tts_recent_text = ""
        self._tts_recent_expiry = 0.0

        # åˆ›å»ºéŸ³é¢‘å¤„ç†çº¿ç¨‹
        self.audio_thread = threading.Thread(target=self.audio_processing_thread, daemon=True)
        self.audio_thread.start()

        self.get_logger().info(
            f"VAD é…ç½®: é˜ˆå€¼={self.vad_threshold}, é™éŸ³æ£€æµ‹={self.silence_duration}s, å‰ç¼“å†²åŒº={self.buffer_history}s, æœ€å°è¯­éŸ³={self.min_speech_duration}s"
        )

    def _to_mono(self, audio_bytes: bytes) -> bytes:
        """å°†å¤šå£°é“int16 PCMä¸‹æ··ä¸ºå•å£°é“ï¼Œä»¥ä¾¿VADä¸è½¬å†™ã€‚"""
        if self.channels == 1:
            return audio_bytes
        try:
            pcm = np.frombuffer(audio_bytes, dtype=np.int16)
            if pcm.size % self.channels != 0:
                pcm = pcm[: (pcm.size // self.channels) * self.channels]
            frames = pcm.reshape(-1, self.channels).astype(np.int32)
            mono = (frames.mean(axis=1)).astype(np.int16)
            return mono.tobytes()
        except Exception:
            return audio_bytes  # å¤±è´¥æ—¶å›é€€

    def calculate_rms(self, audio_data):
        """è®¡ç®—éŸ³é¢‘RMS (å‡æ–¹æ ¹) ç”¨äºVADï¼ˆå‡å®šå•å£°é“å­—èŠ‚ï¼‰"""
        audio_np = np.frombuffer(audio_data, dtype=np.int16)
        if audio_np.size == 0:
            return 0.0
        rms = np.sqrt(np.mean(audio_np.astype(np.float64) ** 2))
        return rms / 32768.0

    def update_background_energy(self, rms):
        """åŠ¨æ€é˜ˆå€¼ï¼šéå†»ç»“æ—¶æ›´æ–°èƒŒæ™¯å™ªå£°ï¼›TTSæœŸæå‡é˜ˆå€¼"""
        if not self._freeze_noise:
            self.energy_history.append(rms)
            if len(self.energy_history) > 10:
                self.background_energy = float(np.percentile(list(self.energy_history), 10))
        base = max(self.background_energy * 2.5, self.vad_threshold)
        if self.tts_playing:
            base *= self.tts_threshold_boost  # TTSæœŸé—´æå‡é˜ˆå€¼
        return base

    def audio_processing_thread(self):
        """éŸ³é¢‘å¤„ç†çº¿ç¨‹ï¼ŒåŒ…å«VADé€»è¾‘"""
        continuous_listening = True  # è¿ç»­ç›‘å¬æ¨¡å¼
        
        while rclpy.ok():
            # è¯»å–éŸ³é¢‘æ•°æ®ï¼ˆå³ä¾¿é—¨æ§ï¼Œä¹Ÿéœ€è¦æ¶ˆè€—æµï¼Œä¾¿äº drainï¼‰
            try:
                raw = self.stream.read(self.chunk_size, exception_on_overflow=False)
            except Exception as e:
                self.get_logger().error(f"éŸ³é¢‘è¯»å–é”™è¯¯: {e}")
                time.sleep(0.05)
                continue

            # ç»Ÿä¸€è½¬ä¸ºå•å£°é“å¤„ç†
            audio_data = self._to_mono(raw)

            current_time = time.time()

            # é—¨æ§åˆ¤å®šï¼ˆTTSè¿›è¡Œä¸­æˆ–æŒ‚èµ·æœŸï¼‰
            gated = self.tts_playing or (self.resume_at and current_time < self.resume_at)

            # é¦–æ¬¡è¿›å…¥é—¨æ§/æŒ‚èµ·åï¼šæ¸…ç©ºç¼“å†²ï¼Œé¿å…å›æ”¾æ®‹ç•™
            if gated and self._should_drain:
                try:
                    self.speech_buffer.clear()
                except Exception:
                    pass
                self.current_speech = bytearray()
                self.silence_counter = 0
                self.speech_counter = 0
                self._should_drain = False
                self.get_logger().debug("å·²æ¸…ç©ºç¼“å†²ä¸çŠ¶æ€ (TTSæœŸé—´/æŒ‚èµ·)")

            # åœ¨é—¨æ§å¹¶ä¸”ä¸å…è®¸æ‰“æ–­æ—¶ï¼šå†»ç»“å™ªå£°ä¼°è®¡å¹¶ç›´æ¥ä¸¢å¼ƒæœ¬è½®æ•°æ®
            if gated and not ALLOW_BARGE_IN:
                self._freeze_noise = True
                time.sleep(0.03)
                continue

            # è‹¥å·²è„±ç¦»é—¨æ§ï¼Œè§£é™¤å†»ç»“
            if (not gated) and self._freeze_noise:
                self._freeze_noise = False
                self.resume_at = 0.0
                self.get_logger().debug("æ¢å¤å™ªå£°ä¼°è®¡")

            try:
                # è®¡ç®—éŸ³é¢‘èƒ½é‡
                rms = self.calculate_rms(audio_data)
                # å½“å‰èƒŒæ™¯èƒ½é‡ç”¨äºSNRåˆ¤å®š
                bg = max(self.background_energy, 1e-6)
                snr_now = rms / bg

                # æ›´æ–°/è·å–åŠ¨æ€é˜ˆå€¼
                dynamic_threshold = self.update_background_energy(rms)
                
                # VAD çŠ¶æ€æœº
                if self.vad_state == "silence":
                    # å§‹ç»ˆä¿æŒå†å²ç¼“å†²åŒºï¼ˆå·²ä¸ºå•å£°é“ï¼‰
                    self.speech_buffer.append(audio_data)
                    
                    # æ£€æµ‹å£°éŸ³æ´»åŠ¨ï¼ˆTTSæœŸé¢å¤–è¦æ±‚SNRé—¨é™ï¼‰
                    if rms > dynamic_threshold and (not gated or snr_now >= SNR_GATE):
                        self.speech_counter += 1
                        if self.speech_counter == 1:
                            self.get_logger().debug(f"æ£€æµ‹åˆ°æ½œåœ¨è¯­éŸ³å¼€å§‹ (RMS: {rms:.4f}, é˜ˆå€¼: {dynamic_threshold:.4f}, SNR: {snr_now:.2f})")
                        if self.speech_counter >= int(self.min_speech_duration * self.sample_rate / self.chunk_size):
                            # æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                            self.vad_state = "speech"
                            self.speech_counter = 0
                            self.silence_counter = 0
                            self.last_speech_time = current_time
                            
                            # å°†å†å²ç¼“å†²åŒºæ·»åŠ åˆ°å½“å‰è¯­éŸ³
                            self.current_speech = bytearray()
                            for buffered_chunk in self.speech_buffer:
                                self.current_speech.extend(buffered_chunk)
                            
                            self.get_logger().info(f"ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ (RMS: {rms:.4f}, é˜ˆå€¼: {dynamic_threshold:.4f}, SNR: {snr_now:.2f})")
                    else:
                        self.speech_counter = 0
                
                elif self.vad_state == "speech":
                    # æ·»åŠ éŸ³é¢‘åˆ°å½“å‰è¯­éŸ³ç¼“å†²åŒºï¼ˆå•å£°é“ï¼‰
                    self.current_speech.extend(audio_data)
                    
                    if rms <= dynamic_threshold * 0.8:
                        self.silence_counter += 1
                        silence_duration = self.silence_counter * self.chunk_size / self.sample_rate
                        
                        if silence_duration >= self.silence_duration:
                            # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
                            self.vad_state = "processing"
                            speech_duration = len(self.current_speech) / (self.sample_rate * 2)
                            self.get_logger().info(f"ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ (æ—¶é•¿: {speech_duration:.2f}s)")
                            
                            # å¤„ç†è¯­éŸ³ï¼ˆè¿‡çŸ­å¿½ç•¥ï¼‰
                            if speech_duration > 0.5:
                                processing_thread = threading.Thread(
                                    target=self.process_speech_chunk,
                                    args=(bytes(self.current_speech), gated),
                                    daemon=True
                                )
                                processing_thread.start()
                            
                            # é‡ç½®çŠ¶æ€
                            self.current_speech = bytearray()
                            self.silence_counter = 0
                            self.vad_state = "silence"
                    else:
                        self.silence_counter = 0
                        self.last_speech_time = current_time

                # è¶…æ—¶ä¿æŠ¤ï¼šå¦‚æœè¯­éŸ³æŒç»­å¤ªä¹…ï¼Œå¼ºåˆ¶å¤„ç†
                if self.vad_state == "speech" and (current_time - self.last_speech_time) > 10.0:
                    self.get_logger().info("â° è¯­éŸ³è¶…æ—¶ï¼Œå¼ºåˆ¶å¤„ç†")
                    speech_data = bytes(self.current_speech)
                    processing_thread = threading.Thread(
                        target=self.process_speech_chunk, 
                        args=(speech_data, gated),
                        daemon=True
                    )
                    processing_thread.start()
                    
                    self.current_speech = bytearray()
                    self.vad_state = "silence"

            except Exception as e:
                self.get_logger().error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                time.sleep(0.05)

    def process_speech_chunk(self, speech_data, gated=False):
        """å¤„ç†æ£€æµ‹åˆ°çš„è¯­éŸ³ç‰‡æ®µï¼ˆspeech_data å·²ä¸ºå•å£°é“PCMï¼‰"""
        # TTSæœŸé—´ä¸”ä¸å…è®¸æ‰“æ–­ï¼šç›´æ¥å¿½ç•¥
        if gated and not ALLOW_BARGE_IN:
            self.get_logger().debug("TTSæœŸ/æŒ‚èµ·ï¼Œä¸å¤„ç†è¯­éŸ³ç‰‡æ®µ")
            return

        if len(speech_data) < self.sample_rate * 2 * 0.3:  # å°äº0.3ç§’çš„è¯­éŸ³å¿½ç•¥
            self.get_logger().debug("è¯­éŸ³ç‰‡æ®µå¤ªçŸ­ï¼Œå¿½ç•¥")
            return

        # è®¡ç®—ç‰‡æ®µSNR
        try:
            seg_np = np.frombuffer(speech_data, dtype=np.int16)
            seg_rms = 0.0 if seg_np.size == 0 else (np.sqrt(np.mean(seg_np.astype(np.float64) ** 2)) / 32768.0)
            bg = max(self.background_energy, 1e-6)
            snr_ratio = seg_rms / bg
        except Exception:
            snr_ratio = None

        try:
            # åˆ›å»ºä¸´æ—¶WAVæ–‡ä»¶ï¼ˆå•å£°é“ï¼‰
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp:
                self.write_wav(tmp.name, speech_data)
                transcript = self.transcribe_file(tmp.name)
                if transcript:
                    self.process_recognized_text(transcript, snr_ratio)
        except Exception as e:
            self.get_logger().error(f"è¯­éŸ³å¤„ç†é”™è¯¯: {e}")

    def write_wav(self, path: str, pcm_bytes: bytes):
        """å†™ WAV å·¥å…·ï¼ˆå•å£°é“ï¼‰"""
        with wave.open(path, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(self.sample_rate)
            wf.writeframes(pcm_bytes)

    @tenacity.retry(stop=tenacity.stop_after_attempt(3),
                    wait=tenacity.wait_exponential(multiplier=1, min=1, max=10))
    def transcribe_file(self, fname: str) -> str:
        """Whisper è°ƒç”¨ï¼Œå¸¦é‡è¯•"""
        try:
            with open(fname, "rb") as f:
                response = self.openai_client.audio.transcriptions.create(
                    model=MODEL_NAME,
                    file=f,
                    # language="en",
                    # prompt="The captain is the wake word. Expect phrases starting with Hi Captain, Hey Captain, or Hello Captain.",
                    temperature=0,
                    response_format="text"
                )
            return response.strip() if isinstance(response, str) else response.strip()
        except Exception as e:
            self.get_logger().error(f"OpenAI API è°ƒç”¨å¤±è´¥: {e}")
            return ""

    def tts_status_callback(self, msg: Bool):
        """TTSçŠ¶æ€å›è°ƒï¼šå¼€å¯é—¨æ§ + æŒ‚èµ· + drain + å†»ç»“èƒŒæ™¯èƒ½é‡"""
        if msg.data:
            self.get_logger().info("æ£€æµ‹åˆ° TTS æ­£åœ¨æ’­æ”¾ï¼Œæš‚åœ/é—¨æ§ç›‘å¬")
            self.tts_playing = True
            self._freeze_noise = True
            self.resume_at = 0.0
            self._should_drain = True
        else:
            self.get_logger().info(f"TTS æ’­æ”¾å®Œæ¯•ï¼Œå»¶è¿Ÿæ¢å¤ç›‘å¬ ({int(RESUME_HANGOVER_SEC*1000)}ms)")
            self.tts_playing = False
            self.resume_at = time.time() + RESUME_HANGOVER_SEC
            self._freeze_noise = True  # æŒ‚èµ·æœŸä»å†»ç»“
            self._should_drain = True

    def llm_response_callback(self, msg: String):
        """ç¼“å­˜æœ€è¿‘TTSæ–‡æœ¬ï¼Œç”¨äºè¯†åˆ«åå…œåº•è¿‡æ»¤"""
        text = (msg.data or '').strip()
        if not text:
            return
        # åœ¨TTSæ’­æ”¾æˆ–åˆšç»“æŸçš„çŸ­æ—¶é—´å†…æ‰æ›´æ–°
        if self.tts_playing or (self.resume_at and time.time() < self.resume_at + 1.0):
            combined = (self._tts_recent_text + ' ' + text).strip()
            self._tts_recent_text = combined[-1000:]
            self._tts_recent_expiry = time.time() + 3.0

    def _normalize_text(self, s: str) -> str:
        s = s.lower().strip()
        s = re.sub(r'[^a-z0-9\s]+', ' ', s)
        s = re.sub(r'\s+', ' ', s)
        return s

    def process_recognized_text(self, text, snr_ratio: float | None = None):
        """å¤„ç†è¯†åˆ«çš„æ–‡æœ¬ï¼Œæ£€æŸ¥å”¤é†’è¯ï¼ˆä»…å¥é¦–ã€è¾¹ç•Œã€SNRé—¨é™ï¼‰ï¼Œå¹¶åšTTSè‡ªå›æ”¾å…œåº•è¿‡æ»¤"""
        if not text:
            return

        # æ–‡æœ¬çº§å…œåº•ï¼šè‹¥ä¸æœ€è¿‘TTSæ–‡æœ¬çš„å‰ç¼€å¼ºåŒ…å«ï¼Œåˆ™ä¸¢å¼ƒ
        now = time.time()
        if self._tts_recent_text and now < self._tts_recent_expiry:
            norm_ref = self._normalize_text(self._tts_recent_text)
            norm_txt = self._normalize_text(text)
            words = norm_txt.split()
            prefix = ' '.join(words[:6])
            if prefix and prefix in norm_ref:
                self.get_logger().info("ä¸¢å¼ƒè‡ªå›æ”¾æ–‡æœ¬(å‰ç¼€åŒ…å«äºæœ€è¿‘TTS)")
                return

        lower_text = text.lower().strip()

        # SNR é—¨é™ï¼ˆå¯é€‰ä½†æ¨èï¼‰ï¼šè¿‡ä½åˆ™æ‹’ç»
        if snr_ratio is not None and snr_ratio < SNR_GATE:
            self.get_logger().info(f"æ‹’ç»ä½SNRç‰‡æ®µ (SNR={snr_ratio:.2f} < {SNR_GATE})")
            return

        # ä¸¥æ ¼æ­£åˆ™ï¼šå¥é¦– + è¯è¾¹ç•Œ
        if self.wake_regex.search(lower_text):
            msg = String()
            msg.data = text
            self.publisher_.publish(msg)
            self.get_logger().info(f"ğŸ”¥ è¯†åˆ«ç»“æœ (å”¤é†’è¯æ¿€æ´» - æ­£åˆ™): {text}")
            return

        # ä»…å¥é¦–æ¨¡ç³ŠåŒ¹é…ï¼ˆé«˜é˜ˆå€¼ï¼‰ï¼Œä¸åšå…¨å¥æ¯”å¯¹
        for word in self.wake_words:
            n = len(word)
            candidate = lower_text[:max(n + 2, n)]  # å…è®¸å°‘é‡é¢å¤–å­—ç¬¦
            ratio = difflib.SequenceMatcher(None, candidate, word).ratio()
            if ratio >= 0.86:
                msg = String()
                msg.data = text
                self.publisher_.publish(msg)
                self.get_logger().info(f"ğŸ”¥ è¯†åˆ«ç»“æœ (å”¤é†’è¯æ¿€æ´» - å¥é¦–æ¨¡ç³Š): {text}")
                return

        self.get_logger().info(f"æœªæ£€æµ‹åˆ°å”¤é†’è¯: {text}")

    def destroy_node(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'stream'):
            self.stream.stop_stream()
            self.stream.close()
        if hasattr(self, 'audio'):
            self.audio.terminate()
        super().destroy_node()

def main(args=None):
    rclpy.init(args=args)
    node = OpenAISTTNodeWithVAD()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if node:
            node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()